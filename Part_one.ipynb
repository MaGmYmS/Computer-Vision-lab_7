{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import concurrent.futures\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, BatchNormalization, LeakyReLU, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и предобработка датасета CelebA\n",
    "def load_image(img_path, img_size):\n",
    "    img = PIL.Image.open(img_path)\n",
    "    img = img.resize(img_size)\n",
    "    return np.array(img)\n",
    "\n",
    "\n",
    "def load_celeb_a(dataset_path, img_size=(64, 64), max_workers=8):\n",
    "    img_paths = glob.glob(os.path.join(dataset_path, '*.jpg'))\n",
    "\n",
    "    data = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(load_image, img_path, img_size) for img_path in img_paths]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(img_paths), desc=\"Загрузка датасета\"):\n",
    "            data.append(future.result())\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3761565367.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    plt.close()a\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Сохранение сгенерированных изображений\n",
    "def save_images(generator_inner, epoch, latent_dim_inner, examples=10):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim_inner))\n",
    "    gen_images = generator_inner.predict(noise)\n",
    "    gen_images = 0.5 * gen_images + 0.5\n",
    "    fig, axs = plt.subplots(1, examples, figsize=(15, 15))\n",
    "    for i in range(examples):\n",
    "        axs[i].imshow(gen_images[i])\n",
    "        axs[i].axis('off')\n",
    "    plt.savefig(f\"gan_images_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Демонстрация результатов генерации\n",
    "def display_generated_images(generator_inner, latent_dim_inner, examples=10):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim_inner))\n",
    "    gen_images = generator_inner.predict(noise)\n",
    "    gen_images = 0.5 * gen_images + 0.5  # Обратная нормализация изображений в диапазон [0, 1]\n",
    "    fig, axs = plt.subplots(1, examples, figsize=(15, 15))\n",
    "    for i in range(examples):\n",
    "        axs[i].imshow(gen_images[i])\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение генератора\n",
    "def build_generator(latent_dim_inner):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8 * 8 * 256, use_bias=False, input_shape=(latent_dim_inner,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# Построение дискриминатора\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "  # Построение и компиляция GAN\n",
    "def build_gan(generator_inner, discriminator_inner):\n",
    "    discriminator_inner.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                                metrics=['accuracy'])\n",
    "    discriminator_inner.trainable = False\n",
    "    gan_input = tf.keras.Input(shape=(latent_dim,))\n",
    "    gan_output = discriminator_inner(generator_inner(gan_input))\n",
    "    gan_inner = tf.keras.Model(gan_input, gan_output)\n",
    "    gan_inner.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение GAN\n",
    "def train_gan(gan_inner, generator_inner, discriminator_inner, data_inner, epochs_inner, batch_size_inner,\n",
    "              latent_dim_inner, save_interval_inner):\n",
    "    real = np.ones((batch_size_inner, 1))\n",
    "    fake = np.zeros((batch_size_inner, 1))\n",
    "    d_loss = -1\n",
    "    g_loss = -1\n",
    "    for epoch in tqdm(range(epochs_inner), desc=\"Обучение GAN\"):\n",
    "        for _ in range(len(data_inner) // batch_size_inner):\n",
    "            idx = np.random.randint(0, data_inner.shape[0], batch_size_inner)\n",
    "            images = data_inner[idx]\n",
    "            noise = np.random.normal(0, 1, (batch_size_inner, latent_dim_inner))\n",
    "            gen_images = generator_inner.predict(noise)\n",
    "            d_loss_real = discriminator_inner.train_on_batch(images, real)\n",
    "            d_loss_fake = discriminator_inner.train_on_batch(gen_images, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            noise = np.random.normal(0, 1, (batch_size_inner, latent_dim_inner))\n",
    "            g_loss = gan_inner.train_on_batch(noise, real)\n",
    "        if epoch % save_interval_inner == 0:\n",
    "            save_images(generator_inner, epoch, latent_dim_inner)\n",
    "            print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные параметры\n",
    "\n",
    "latent_dim = 100\n",
    "img_shape = (32, 32, 3)\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "save_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и нормализация данных\n",
    "dataset_path = 'img_align_celeba'  # Укажите путь к датасету CelebA\n",
    "print(\"Начинаю загрузку датасета\")\n",
    "data = load_celeb_a(dataset_path)\n",
    "print(\"Датасет загружен\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для нормализации данных\n",
    "def normalize_data(data_chunk):\n",
    "    return (data_chunk - 127.5) / 127.5\n",
    "\n",
    "# Размер пакета\n",
    "batch_size = 10000\n",
    "normalized_data = []\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size), desc=\"Нормализацяи датасета\"):\n",
    "    batch = data[i:i + batch_size].astype(np.float32)\n",
    "    normalized_batch = normalize_data(batch)\n",
    "    normalized_data.append(normalized_batch)\n",
    "\n",
    "# Объединение всех нормализованных пакетов\n",
    "data = np.concatenate(normalized_data, axis=0)\n",
    "print(\"Датасет нормализован\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание моделей\n",
    "print(\"Создаю модель\")\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(img_shape)\n",
    "gan = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "print(\"Начинаю обучение модели\")\n",
    "train_gan(gan, generator, discriminator, data, epochs, batch_size, latent_dim, save_interval)\n",
    "\n",
    "display_generated_images(generator, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
